[
  {
    "path": "posts/2021-06-25-using-patchwork-for-neat-visualisations/",
    "title": "Using {patchwork} for neat visualisations",
    "description": "I present an example of how I used {patchwork} to present density plots for my PhD results chapter. I simulate data based on the results from my PhD to illustrate my learnings.",
    "author": [
      {
        "name": "Maxine Schaefer",
        "url": {
          "https://maxinenschaefer.github.io/MaxineSchaefer/posts/2021-06-25-using-patchwork-for-neat-visualisations/": {}
        }
      }
    ],
    "date": "2021-06-25",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nSet up\r\nSimulate data (with some context)\r\nVisualisation\r\nPlot 1 - L1 task administration\r\nPlot 2 - English task adminstration\r\nAdd the graphs together using {patchwork}\r\n\r\nA note on data simulation\r\n\r\n\r\nIntroduction\r\nI am working on the descriptive statistics section of the Grade 1 sample of my PhD. I thought I’d share how I used {patchwork} for one of the plots, using simulated data based on my PhD data.\r\nRecently I have become interested in data simulation, especially since I, unfortunately, did not know about open science until I had already asked for informed consent from my participants’ guardians. I cannot share the data from my PhD, but I can share simulated data from it. I recently attended some sessions of the very useful Psychology Postgraduate Affairs Group (PsyPAG) & MSCP-Section Simulation Summer School (resources here) where I picked up tips on simulating data for linear models and linear fixed effects models. It was a lot to take in, so in this post, I only apply what I learned about simulating a dataset from Andrew Hales’ session on 9 June 2021.\r\nI also need to give a special shout out to the wonderful people who put all the answers to my frequently searched {ggplot2} questions in one neat tutorial. If you’re like me please go, RIGHT NOW, and bookmark this Intro to Data Viz tutorial from PsyTeachR. I learned about {patchwork} from that tutorial.\r\nAlright, now for the task at hand. In this blog, I simulate rapid automatised naming (RAN) data based on the results of participants in my PhD then present a density plot of the distribution of scores for different tasks (letters, digits, colours and objects) per language group (isiXhosa and isiZulu) and per language of administration (first language and English).\r\nSet up\r\nLoad packages.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(patchwork)\r\nlibrary(jtools)\r\n\r\n\r\n\r\nSimulate data (with some context)\r\nSince I did not ask for permission to share the data from my PhD, I need to simulate the data based on the summary statistics from my Grade 1 sample. I suppose a summary of what I am doing is needed.\r\nI am examining how phonological processing skills (phonological awareness, rapid automatised naming and phonological working memory) develop over time and contribute to literacy development in children’s first language (L1; isiXhosa or isiZulu) and additional language (English). I collected data from isiXhosa-English and isiZulu-English emergent bilingual children who attended schools where the medium of instruction matched their first language. All constructs where measured with more than one task in both L1 and English. For the blog at hand, I refer only to the distribution of scores for the rapid automatised naming (RAN) task.\r\nA RAN task requires a participant to name a set of six items (either digits, letters, colours or objects) in an array of 9 by 4 as fast as they can. The final score is the total number of seconds taken to name all items. RAN is a predictor of reading fluency.\r\nFor the data simulation, I simulated data for id, language, and the different RAN tasks (digits, letters, objects, colours). Because of educational practices, and based on the pilot study, RAN letters was only administered in L1, and RAN colours and RAN digits was only administered in English. I used the mean and standard deviations from these tasks to simulate data for this blog. I simulated the data separately for each language group in the study and then combined the datasets using rbind().\r\n\r\n\r\nsample_size <- 70 # set sample size (this number differs from my PhD)\r\n\r\nset.seed(1405)    # set seed for reprodicibility\r\n\r\n# simulate data for group 1 (in wide format)\r\nxhosa <- data.frame(\r\n   \"id\" = rep(1:sample_size),   # give the participants unique IDs\r\n   \"language\" = \"isiXhosa\",        # assign participants to isiXhosa group\r\n   \r\n   #simulate data based on summary stats from my project\r\n   \"L1_ran_let_time\" = rnorm(n = sample_size, mean = 53, sd = 20),\r\n   \"L1_ran_obj_time\" = rnorm(n = sample_size, mean = 56, sd = 13),\r\n   \"English_ran_dig_time\" = rnorm(n = sample_size, mean = 47, sd = 16),\r\n   \"English_ran_obj_time\" = rnorm(n = sample_size, mean = 77, sd = 22),\r\n   \"English_ran_col_time\" = rnorm(n = sample_size, mean = 71, sd = 23)\r\n   )\r\n\r\n# simulate data for group 2 (in wide format)\r\nzulu <- data.frame(\r\n   \"id\" = rep((sample_size +1):(sample_size*2)),   # give the participants unique IDs\r\n   \"language\" = \"isiZulu\",                            # assign participants to isiZulu group\r\n   \r\n   #simulate data based on summary stats from my project\r\n   \"L1_ran_let_time\" = rnorm(n = sample_size, mean = 49, sd = 22),\r\n   \"L1_ran_obj_time\" = rnorm(n = sample_size, mean = 55, sd = 12),\r\n   \"English_ran_dig_time\" = rnorm(n = sample_size, mean = 47, sd = 18),\r\n   \"English_ran_obj_time\" = rnorm(n = sample_size, mean = 64, sd = 16),\r\n   \"English_ran_col_time\" = rnorm(n = sample_size, mean = 57, sd = 18)\r\n   )\r\n\r\n# join datasets\r\nsim_data <- rbind(xhosa, zulu)\r\n\r\n\r\n\r\nThe simulated data is in wide format. To create the graph I want, I need to convert the data to long form. The PsyteachR tutorial also explains how to do this, but I first learned how to do this from Emma James and colleagues’ open data for their 2021 paper on “The relations between morphological awareness and reading comprehension in beginner readers to young adolescents”.\r\nThe code below shows how I use pivot_longer() to convert the data from wide to long format so that each observation occupies a row.\r\n\r\n\r\nsim_data_long <- sim_data %>% \r\n  pivot_longer(3:7, names_to = \"task\", values_to = \"score\") \r\nhead(sim_data_long)\r\n\r\n\r\n# A tibble: 6 x 4\r\n     id language task                 score\r\n  <int> <chr>    <chr>                <dbl>\r\n1     1 isiXhosa L1_ran_let_time       58.4\r\n2     1 isiXhosa L1_ran_obj_time       67.5\r\n3     1 isiXhosa English_ran_dig_time  50.0\r\n4     1 isiXhosa English_ran_obj_time  36.5\r\n5     1 isiXhosa English_ran_col_time  75.0\r\n6     2 isiXhosa L1_ran_let_time       60.1\r\n\r\ntask still contains data for two variables: the language of the task and the task itself. I separate these values using separate() using the underscore in the task name, then I convert the character variables to factors to make it easier to plot.\r\n\r\n\r\nsim_data_long <- sim_data %>% \r\n  pivot_longer(3:7, names_to = \"task\", values_to = \"score\") %>%   # change to long format\r\n  separate(col = task, into = c(\"tasklang\", \"task\"), sep = \"_\", extra = \"merge\") %>%  # separate language of administration from task\r\n  mutate(across(c(language, tasklang,task), as_factor)) # change character variables into factors\r\nhead(sim_data_long)\r\n\r\n\r\n# A tibble: 6 x 5\r\n     id language tasklang task         score\r\n  <int> <fct>    <fct>    <fct>        <dbl>\r\n1     1 isiXhosa L1       ran_let_time  58.4\r\n2     1 isiXhosa L1       ran_obj_time  67.5\r\n3     1 isiXhosa English  ran_dig_time  50.0\r\n4     1 isiXhosa English  ran_obj_time  36.5\r\n5     1 isiXhosa English  ran_col_time  75.0\r\n6     2 isiXhosa L1       ran_let_time  60.1\r\n\r\nVisualisation\r\nI want to show the distribution of the scores for each task for each language group and each language of task administration. Unfortunately, you can only really represent three variables at a time in one visualisation (well, anyway, I only know how to show three!). I decided to create two plots, one for each language of administration.\r\nTo do this, I assigned one variable to x in ggplot (i.e. score), one variable to fill and colour (i.e. language), and one variable to facet_wrap() (i.e. task). I then filtered by language of task administration (i.e. tasklang) so that I would have one visualisation for L1 and one for English. Once I have both graphs, I group them together neatly using {patchwork}.\r\nPlot 1 - L1 task administration\r\nHere, I filtered the data so that only the L1 data was included. I planned to have this plot at the top since it included fewer tasks than the English administration.\r\n\r\n\r\np1 <- sim_data_long %>%   \r\n  filter(tasklang == \"L1\") %>%   # visualise data for L1 only\r\n  \r\n  # rename for neater graph\r\n  mutate(\r\n    task = case_when(\r\n      task == \"ran_col_time\" ~ \"Colours\",\r\n      task == \"ran_dig_time\" ~ \"Digits\",\r\n      task == \"ran_let_time\" ~ \"Letters\",\r\n      task == \"ran_obj_time\" ~ \"Objects\")) %>% \r\n  \r\n  # add base plot\r\n  ggplot(aes(x = score, # distribution of scores\r\n             colour = language, fill = language)) + # colour and fill for each language group\r\n  \r\n  # density graph with colours\r\n  geom_density(alpha = .3) +  # add density geom with alpha at .3 for easer view of each language group\r\n  scale_colour_viridis_d(name = \"Language\", option = \"E\") +\r\n  scale_fill_viridis_d(name = \"Language\", option = \"E\") +\r\n  \r\n  # add theme\r\n  theme_apa()  +  # use APA theme from jtools\r\n  theme(plot.title = element_text(size = 12, face = \"plain\", hjust = .5)) +  # specify size, face and position of title\r\n  \r\n  # edit axes\r\n  labs(x = NULL, y = \"Density\", title = \"L1\") +  # no x axis label since we will add this plot to another one\r\n  xlim(0, 150) +    # set x axis limits\r\n  guides(fill = FALSE, color = FALSE) +  # hide the legend since it will be in the second graph\r\n  \r\n  facet_wrap(~task) # use facet_wrap so that each task has its own panel\r\n\r\np1 # print visualisation\r\n\r\n\r\n\r\n\r\nPlot 2 - English task adminstration\r\nHere, I filtered the data so that only the English data was included.\r\n\r\n\r\np2 <- sim_data_long %>% \r\n  \r\n  filter(tasklang == \"English\") %>%  # use only English data\r\n  \r\n  # rename for neater graph\r\n  mutate(task = case_when(\r\n      task == \"ran_col_time\" ~ \"Colours\",\r\n      task == \"ran_dig_time\" ~ \"Digits\",\r\n      task == \"ran_let_time\" ~ \"Letters\",\r\n      task == \"ran_obj_time\" ~ \"Objects\")) %>% \r\n  \r\n  # base layer\r\n  ggplot(aes(x = score, \r\n             colour = language, fill = language)) +\r\n  \r\n  # density graph with colours\r\n  geom_density(alpha = .3) +\r\n  scale_colour_viridis_d(name = \"Language\", option = \"E\") +\r\n  scale_fill_viridis_d(name = \"Language\", option = \"E\") +\r\n  \r\n  # add theme\r\n  theme_apa()  + \r\n  theme(legend.position = \"bottom\", # place the legend at the bottom of the graph\r\n        plot.title = element_text(size = 12, face = \"plain\", hjust = .5)) +\r\n  \r\n  # edit axes\r\n  labs(x = \"Time (seconds)\", y = \"Density\", title = \"English\") + # add label for y\r\n  xlim(0, 150) +\r\n  \r\n  facet_wrap(~factor(task, \r\n                     levels = c(\"Digits\", \"Objects\", \"Colours\"),  # specify the order of the labels for each facet\r\n                     labels = c(\"Digits\", \"Objects\", \"Colours\"))) # specify the labels for each facet\r\n\r\np2\r\n\r\n\r\n\r\n\r\nAdd the graphs together using {patchwork}\r\nAfter first reading about {patchwork} in the IntroDataViz tutorial of PsyTeachR I also found the Patchwork website helpful.\r\nNow, I wanted to present the two graphs together making sure that the axes of letters/digits and objects overlap because these tasks can be directly compared to one another. The digit and letter RAN both measure alphanumeric RAN and the objects task is directly comparable for each language of administration.{patchwork} can be used to assemble the graphs exactly how you want using the operators +, |, and / as well as the plot_layout() function.\r\nHere are the non-fiddly options using the operators. + places plots next to one another.\r\n\r\n\r\np1 + p2\r\n\r\n\r\n\r\n\r\nUsing | gives the same output as +. Maybe I am doing something wrong?\r\n\r\n\r\np1 | p2\r\n\r\n\r\n\r\n\r\nUse / to place the first plot on top of the second plot. This is OK because the plots fit into a neat rectangle, however, it does not allow the clear comparison between the letters/digits and objects in each language of test administration.\r\n\r\n\r\np1 / p2\r\n\r\n\r\n\r\n\r\nIn the end, to make the graphs line up exactly how I wanted, I defined a layout to use where # is a space and the letters refer to different graphs.\r\n\r\n\r\nlayout <- \"\r\nAA#\r\nBBB\r\n\"\r\n\r\np1 /p2 + \r\n  plot_layout(design = layout) \r\n\r\n\r\n\r\n\r\nAh, I very much like this plot. It shows how the isiZulu group names objects and colours faster than the isiXhosa group. While I am yet to discuss this in my PhD chapter, I think this between-groups difference results from vocabulary differences in the groups with the isiZulu group having a larger English vocabulary (stay tuned for my PhD dissertation!).\r\nAnd for comparison, here is the plot based on ‘real’ data from my Phd. \r\nA note on data simulation\r\nData simulation doesn’t solve the world of problems. I calculated the summary statistics of this data simulation below.\r\n\r\n\r\nsim_data_long %>% \r\n  group_by(language, tasklang, task) %>% \r\n  summarise(mean = mean(score),\r\n            SD = sd(score),\r\n            min = min(score),\r\n            max = max(score)) %>% \r\n  arrange(task, tasklang)\r\n\r\n\r\n# A tibble: 10 x 7\r\n# Groups:   language, tasklang [4]\r\n   language tasklang task          mean    SD   min   max\r\n   <fct>    <fct>    <fct>        <dbl> <dbl> <dbl> <dbl>\r\n 1 isiXhosa L1       ran_let_time  53.3  19.6 -4.37 104. \r\n 2 isiZulu  L1       ran_let_time  50.0  21.3  4.08 102. \r\n 3 isiXhosa L1       ran_obj_time  56.9  13.6 20.0   88.4\r\n 4 isiZulu  L1       ran_obj_time  57.7  13.2 29.1   89.5\r\n 5 isiXhosa English  ran_obj_time  76.5  21.4 31.8  123. \r\n 6 isiZulu  English  ran_obj_time  64.2  17.2 28.6  100. \r\n 7 isiXhosa English  ran_dig_time  47.2  16.9  3.49  94.1\r\n 8 isiZulu  English  ran_dig_time  47.3  19.7  1.71  92.5\r\n 9 isiXhosa English  ran_col_time  68.2  20.8 18.1  132. \r\n10 isiZulu  English  ran_col_time  58.2  14.6 29.4   92.9\r\n\r\nYou’ll notice that the minimum time for RAN letters for the isiXhosa group in L1 is -4.4 seconds. This value and some of the other minimum values are not plausible for reaction time data to name 36 items. I have not yet learned how to simulate data that better matches reaction time data. I suppose that this is just a warning that simulated data cannot really supplement the real thing.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-25-using-patchwork-for-neat-visualisations/density_ran.png",
    "last_modified": "2021-06-26T08:17:09+02:00",
    "input_file": {},
    "preview_width": 2125,
    "preview_height": 1417
  },
  {
    "path": "posts/2021-06-19-tidy-tuesday-2021-03-16-video-games-and-sliced/",
    "title": "Tidy Tuesday 2021-03-16: Video Games and Sliced",
    "description": "For my first independent attempt at TidyTuesday I tackled a subject close to my husband's heart: Dota 2.",
    "author": [
      {
        "name": "Maxine Schaefer",
        "url": {}
      }
    ],
    "date": "2021-06-19",
    "categories": [],
    "contents": "\r\nI recently attended a guided TidyTuesday hosted by RLadies Freiburg and wanted to apply what I had learned to a new data set. I went to the TidyTuesday Github repo. Once there I found the Video Games and Sliced dataset. This dataset looked interesting to me because (1) it was about gaming which is a topic often spoken about in my household, and (2) it was a relatively small dataset containing only seven variables.\r\nIn this post, I’ll first give a narrative summary of what I did. I include all the code and the final visualisation at the end of the post. You can find all the code at the TidyTuesday repo on Github.\r\nFirst, load packages with library(). I loaded {tidyverse} and {tidytuesdayR}. I downloaded the data from Github using {tidytuesdayR} as indicated in the repo that contains the data. I soon realised you cannot keep downloading the data from online so I saved the data to a .csv file.\r\nI next peaked at the data using View(). This function shows you the data in the dataviewer. However, one also needs to summarise the data to see what one is working with. I used skim() from {skimr} for this overview. I also noted the data type of each variable.\r\nI decided to focus on Dota 2 because this is a game my husband loves to play. I also wanted to look at the peak number of players per month and how this changed over a year. I decided on 2019 since it was the last ‘normal’ year, and because I remember having the chance to open some of the prizes in my husband’s Battle Pass before The International. For those who don’t know, The International is the main and largest competition of the Dota 2 season each year. Thus, for my visualisation I added some data on the start and end dates of TI, and included the value of the total prize pool.\r\nWhat did I find? Peak player numbers do go up during TI, but do not reach the peak number of players in March.\r\nPeak number (in thousands) of Dota 2 players in 2019In keeping with the Dota 2 ‘feel’ I made the visualisation dark. I even asked my husband, Mark, for some tips to make it feel more like Dota 2. We ended up with red as the colour. I am not sure I am in love with it, but I’m still proud of my first TidyTuesday attempt.\r\nHere’s the code to make the plot.\r\n\r\n\r\n# libraries\r\nlibrary(tidytuesdayR) # only to initially download data\r\nlibrary(tidyverse)\r\nlibrary(ggdark) # for dark minimal theme\r\n\r\n# Download and save data\r\ntuesdata <- tidytuesdayR::tt_load('2021-03-16')\r\ndat <- tuesdata$games\r\n\r\n# Check out the data\r\nView(dat)\r\nskimr::skim(dat)\r\n\r\n# TI start and end\r\nTIstart <- (7/30) + 7 # TI starts 7 of July, convert the 7th day into a decimal and add to 7th month\r\nTIend <- (26/30) + 8 # TI ends 26 Aug, convert the 26th day into a decimal and add to 8th month\r\n\r\n# Generate graph\r\n\r\np_final <- \r\n  \r\n  # get data ready\r\n dat %>% \r\n  \r\n  # filter data to include only Dota 2 for 2019\r\n  filter(gamename == \"Dota 2\", # keep only Dota 2\r\n         year == 2019) %>%     # keep only year 2019\r\n  \r\n  # make axis more readable\r\n  mutate(peak_in_thousands = round((peak/1000), 0 )) %>% # reduce numbers on the graph by dividing by 1000\r\n  \r\n  # convert months to numbers so that the months are listed in order in the graph\r\n  mutate(month = case_when(   \r\n    month == \"January\" ~ 1,\r\n    month == \"February\" ~ 2,\r\n    month == \"March\" ~ 3,\r\n    month == \"April\" ~ 4,\r\n    month == \"May\" ~ 5,\r\n    month == \"June\" ~ 6,\r\n    month == \"July\" ~ 7,\r\n    month == \"August\" ~ 8,\r\n    month == \"September\" ~ 9,\r\n    month == \"October\" ~ 10,\r\n    month == \"November\" ~ 11,\r\n    month == \"December\" ~ 12\r\n  )) %>% mutate(month = as.numeric(month)) %>%  # convert to numeric so that the months will be listed in order\r\n\r\n\r\n# base graph\r\n ggplot(aes(x = month, y = peak_in_thousands)) + \r\n  geom_point(shape = 17, size = 3) + # add points\r\n  geom_line(linetype = 5) + # add lines to join points\r\n  \r\n  # add labels\r\n  labs(x = \"Month in 2019\",  \r\n       y = \"Peak number of players in thousands\",\r\n       title = \"PEAK NUMBER OF DOTA 2 PLAYERS\",\r\n       subtitle = \"per month in 2019\", \r\n       caption = \"Data source: TidyTuesday 2021-03-16\r\n       @MaxineNSchaefer\") +\r\n  \r\n  # fix axis breaks and limits\r\n  scale_x_continuous(n.breaks = 12) + # have a break for each month\r\n  scale_y_continuous(limits = c(0, 1100), breaks = c(0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100)) + # start at 0\r\n  \r\n  # add start and end dates of The International which I got from https://liquipedia.net/dota2/The_International/2019#Viewership_Stats\r\n  geom_vline(xintercept = TIstart, color = \"#cc0000\") + # add start date and color using Dota 2 colour\r\n  geom_vline(xintercept = TIend, color = \"#cc0000\") + # add end date and color using Dota 2 colour\r\n  \r\n    # add label for TI, and prize pool\r\n  annotate(geom=\"text\", x=8, y=450, label=\"TI 9\", color=\"#cc0000\", size = 6) + # add text to graph \r\n  annotate(geom=\"text\", x=10, y=450, label= # add text to indicate prize pool value\r\n  \"Prize pool\r\n  34.33 mil USD\", color=\"#cc0000\", size = 4) +\r\n  \r\n  # edit theme\r\ndark_theme_minimal() + # add basic dark theme from {ggdark}\r\n  \r\n  # edit theme to match Dota 2 colours more or less\r\n  theme(axis.title = element_text(colour = \"#b22222\", face = \"bold\"),\r\n        plot.title = element_text(size = 20, colour = \"#cc0000\", face = \"bold\", family = \"serif\"), #change the font for the title\r\n        plot.subtitle = element_text(colour = \"#cc0000\"),\r\n        plot.caption = element_text(colour = \"#b22222\"),\r\n        axis.text = element_text(colour = \"#b22222\"),\r\n        panel.grid.major = element_blank(), # remove grid lines\r\n        panel.grid.minor = element_blank())  # remove grid lines\r\n\r\np_final\r\n# ggsave(\"final_plot.png\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-19-tidy-tuesday-2021-03-16-video-games-and-sliced/final_plot.png",
    "last_modified": "2021-06-26T08:17:45+02:00",
    "input_file": {},
    "preview_width": 2100,
    "preview_height": 2100
  },
  {
    "path": "posts/2021-06-18-welcome/",
    "title": "Welcome",
    "description": "Introducing myself.",
    "author": [
      {
        "name": "Maxine Schaefer",
        "url": {}
      }
    ],
    "date": "2021-06-18",
    "categories": [],
    "contents": "\r\nHi!\r\nWelcome to my blog. I described this post as introducing myself.\r\nWho am I? In a bid to stop defining myself by my work, maybe I could say that I am a nature lover who does not get out nearly enough; I like to occupy my time learning new things, listening to audiobooks (I’m on an Enderverse binge at the moment), and looking after my indoor plants. If I did have to mention work, I’d say that I am a researcher and teacher. I’ve studied Linguistics, but my research currently fits more closely in the sub-discipline of Applied Linguistics.\r\nI am hoping that this website will be a place for me to keep a record of what I’ve done and what I’m interested in. After getting a little more used to R I wanted to see if I would be able to make a website (and keep it running). Since I’m always having to Google the same things when it comes to my own analysis, I hope to also set up some posts to remind myself how to do things. Maybe this could be useful to you too.\r\nAnyway, please get in touch if you’d like to say “hi!”. The relevant contacts are available on the home page.\r\nStaring ahead at the future of possibilities 📍 Hogsback, South Africa 📷 Mark Schaefer\r\n\r\n\r\n",
    "preview": "posts/2021-06-18-welcome/hogsback.jpg",
    "last_modified": "2021-06-19T21:06:37+02:00",
    "input_file": {}
  }
]
